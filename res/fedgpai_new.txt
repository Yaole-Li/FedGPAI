❯ python air.py
正在加载 Air 数据集...
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Aotizhongxin = data_Aotizhongxin.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Changping = data_Changping.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Dingling = data_Dingling.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Dongsi = data_Dongsi.replace(wind_direction[i], i).infer_objects(copy=False)
初始化随机特征...
使用设备: cuda:0
开始联邦学习训练 (20 轮全局训练, 5 轮本地训练)...

全局轮次 1/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 1, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 1, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 1, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 1, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 1, 样本 200
    将执行 5 轮本地训练

  当前轮次 1 的MAE为: 0.121895
  模型已保存到: checkpoints/fedgpai_checkpoint_epoch_1.pt

全局轮次 2/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 2, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 2, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 2, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 2, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 2, 样本 200
    将执行 5 轮本地训练

全局轮次 3/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 3, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 3, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 3, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 3, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 3, 样本 200
    将执行 5 轮本地训练

全局轮次 4/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 4, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 4, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 4, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 4, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 4, 样本 200
    将执行 5 轮本地训练

全局轮次 5/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 5, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 5, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 5, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 5, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 5, 样本 200
    将执行 5 轮本地训练

  当前轮次 5 的MAE为: 0.107280
  模型已保存到: checkpoints/fedgpai_checkpoint_epoch_5.pt

全局轮次 6/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 6, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 6, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 6, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 6, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 6, 样本 200
    将执行 5 轮本地训练

全局轮次 7/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 7, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 7, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 7, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 7, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 7, 样本 200
    将执行 5 轮本地训练

全局轮次 8/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 8, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 8, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 8, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 8, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 8, 样本 200
    将执行 5 轮本地训练

全局轮次 9/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 9, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 9, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 9, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 9, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 9, 样本 200
    将执行 5 轮本地训练

全局轮次 10/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 10, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 10, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 10, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 10, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 10, 样本 200
    将执行 5 轮本地训练

  当前轮次 10 的MAE为: 0.106715
  模型已保存到: checkpoints/fedgpai_checkpoint_epoch_10.pt

全局轮次 11/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 11, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 11, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 11, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 11, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 11, 样本 200
    将执行 5 轮本地训练

全局轮次 12/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 12, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 12, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 12, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 12, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 12, 样本 200
    将执行 5 轮本地训练

全局轮次 13/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 13, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 13, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 13, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 13, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 13, 样本 200
    将执行 5 轮本地训练

全局轮次 14/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 14, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 14, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 14, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 14, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 14, 样本 200
    将执行 5 轮本地训练

全局轮次 15/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 15, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 15, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 15, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 15, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 15, 样本 200
    将执行 5 轮本地训练

  当前轮次 15 的MAE为: 0.106062
  模型已保存到: checkpoints/fedgpai_checkpoint_epoch_15.pt

全局轮次 16/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 16, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 16, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 16, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 16, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 16, 样本 200
    将执行 5 轮本地训练

全局轮次 17/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 17, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 17, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 17, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 17, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 17, 样本 200
    将执行 5 轮本地训练

全局轮次 18/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 18, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 18, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 18, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 18, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 18, 样本 200
    将执行 5 轮本地训练

全局轮次 19/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 19, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 19, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 19, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 19, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 19, 样本 200
    将执行 5 轮本地训练

全局轮次 20/20
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 20, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 20, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 20, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 20, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 20, 样本 200
    将执行 5 轮本地训练

  当前轮次 20 的MAE为: 0.104478
  模型已保存到: checkpoints/fedgpai_checkpoint_epoch_20.pt
FedGPAI的MSE为：0.010915718972682953
FedGPAI的标准差为：0.005381516180932522

-------------------------------------------------------------
❯ python air.py
FedGPAI_Air_400_20
正在加载 Air 数据集...
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Aotizhongxin = data_Aotizhongxin.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Changping = data_Changping.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Dingling = data_Dingling.replace(wind_direction[i], i).infer_objects(copy=False)
/home/lyl/works/python_work/papers/fl/FedGPAI/lib/datasets/air/data_processor.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  data_Dongsi = data_Dongsi.replace(wind_direction[i], i).infer_objects(copy=False)
初始化随机特征...
使用设备: cuda:0
检查点将保存到: checkpoints/FedGPAI_400_20
开始联邦学习训练 (20 轮全局训练, 5 轮本地训练)...

全局轮次 1/20
训练前 | GPU: 3317.7/16303.0 MB (Free: 12985.3 MB) | RAM: 690.2 MB
/home/lyl/miniconda3/envs/flbench/lib/python3.10/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/home/lyl/works/python_work/papers/fl/FedGPAI/air.py:37: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
清理后 轮次1 | GPU: 3317.7/16303.0 MB (Free: 12985.3 MB) | RAM: 693.7 MB
当前活跃张量数: 6, 总大小: 7.64 MB
本轮训练耗时: 0.12秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 1, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 1, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 1, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 1, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 1, 样本 200
    将执行 5 轮本地训练

  当前轮次 1 的MSE为: 0.013672, MAE为: 0.116926
  模型已保存到: checkpoints/FedGPAI_400_20/epoch_1.pt

全局轮次 2/20
训练前 | GPU: 3370.3/16303.0 MB (Free: 12932.7 MB) | RAM: 1111.5 MB
清理后 轮次2 | GPU: 3370.3/16303.0 MB (Free: 12932.7 MB) | RAM: 1113.3 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 2, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 2, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 2, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 2, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 2, 样本 200
    将执行 5 轮本地训练

全局轮次 3/20
训练前 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1115.8 MB
清理后 轮次3 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1117.3 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 3, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 3, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 3, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 3, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 3, 样本 200
    将执行 5 轮本地训练

全局轮次 4/20
训练前 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1145.9 MB
清理后 轮次4 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1145.9 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 4, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 4, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 4, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 4, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 4, 样本 200
    将执行 5 轮本地训练

全局轮次 5/20
训练前 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
清理后 轮次5 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 5, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 5, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 5, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 5, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 5, 样本 200
    将执行 5 轮本地训练

  当前轮次 5 的MSE为: 0.009135, MAE为: 0.095577
  模型已保存到: checkpoints/FedGPAI_400_20/epoch_5.pt

全局轮次 6/20
训练前 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
清理后 轮次6 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 6, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 6, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 6, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 6, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 6, 样本 200
    将执行 5 轮本地训练

全局轮次 7/20
训练前 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
清理后 轮次7 | GPU: 3371.7/16303.0 MB (Free: 12931.3 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 7, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 7, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 7, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 7, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 7, 样本 200
    将执行 5 轮本地训练

全局轮次 8/20
训练前 | GPU: 3336.6/16303.0 MB (Free: 12966.4 MB) | RAM: 1187.4 MB
清理后 轮次8 | GPU: 3336.6/16303.0 MB (Free: 12966.4 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 8, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 8, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 8, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 8, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 8, 样本 200
    将执行 5 轮本地训练

全局轮次 9/20
训练前 | GPU: 3340.2/16303.0 MB (Free: 12962.8 MB) | RAM: 1187.4 MB
清理后 轮次9 | GPU: 3340.2/16303.0 MB (Free: 12962.8 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 9, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 9, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 9, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 9, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 9, 样本 200
    将执行 5 轮本地训练

全局轮次 10/20
训练前 | GPU: 3339.7/16303.0 MB (Free: 12963.3 MB) | RAM: 1187.4 MB
清理后 轮次10 | GPU: 3339.7/16303.0 MB (Free: 12963.3 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 10, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 10, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 10, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 10, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 10, 样本 200
    将执行 5 轮本地训练

  当前轮次 10 的MSE为: 0.008169, MAE为: 0.090384
  模型已保存到: checkpoints/FedGPAI_400_20/epoch_10.pt

全局轮次 11/20
训练前 | GPU: 3333.5/16303.0 MB (Free: 12969.5 MB) | RAM: 1187.4 MB
清理后 轮次11 | GPU: 3333.5/16303.0 MB (Free: 12969.5 MB) | RAM: 1187.4 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 11, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 11, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 11, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 11, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 11, 样本 200
    将执行 5 轮本地训练

全局轮次 12/20
训练前 | GPU: 3331.5/16303.0 MB (Free: 12971.5 MB) | RAM: 1187.4 MB
清理后 轮次12 | GPU: 3331.5/16303.0 MB (Free: 12971.5 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 12, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 12, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 12, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 12, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 12, 样本 200
    将执行 5 轮本地训练

全局轮次 13/20
训练前 | GPU: 3333.5/16303.0 MB (Free: 12969.5 MB) | RAM: 1187.5 MB
清理后 轮次13 | GPU: 3333.5/16303.0 MB (Free: 12969.5 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: -1.44秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 13, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 13, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 13, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 13, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 13, 样本 200
    将执行 5 轮本地训练

全局轮次 14/20
训练前 | GPU: 3333.0/16303.0 MB (Free: 12970.0 MB) | RAM: 1187.5 MB
清理后 轮次14 | GPU: 3333.0/16303.0 MB (Free: 12970.0 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 14, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 14, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 14, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 14, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 14, 样本 200
    将执行 5 轮本地训练

全局轮次 15/20
训练前 | GPU: 3335.0/16303.0 MB (Free: 12968.0 MB) | RAM: 1187.5 MB
清理后 轮次15 | GPU: 3335.0/16303.0 MB (Free: 12968.0 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 15, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 15, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 15, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 15, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 15, 样本 200
    将执行 5 轮本地训练

  当前轮次 15 的MSE为: 0.007768, MAE为: 0.088133
  模型已保存到: checkpoints/FedGPAI_400_20/epoch_15.pt

全局轮次 16/20
训练前 | GPU: 3322.7/16303.0 MB (Free: 12980.3 MB) | RAM: 1187.5 MB
清理后 轮次16 | GPU: 3322.7/16303.0 MB (Free: 12980.3 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 16, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 16, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 16, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 16, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 16, 样本 200
    将执行 5 轮本地训练

全局轮次 17/20
训练前 | GPU: 3324.7/16303.0 MB (Free: 12978.3 MB) | RAM: 1187.5 MB
清理后 轮次17 | GPU: 3324.7/16303.0 MB (Free: 12978.3 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.09秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 17, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 17, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 17, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 17, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 17, 样本 200
    将执行 5 轮本地训练

全局轮次 18/20
训练前 | GPU: 3411.4/16303.0 MB (Free: 12891.6 MB) | RAM: 1187.5 MB
清理后 轮次18 | GPU: 3411.4/16303.0 MB (Free: 12891.6 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 18, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 18, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 18, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 18, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 18, 样本 200
    将执行 5 轮本地训练

全局轮次 19/20
训练前 | GPU: 3413.4/16303.0 MB (Free: 12889.6 MB) | RAM: 1187.5 MB
清理后 轮次19 | GPU: 3413.4/16303.0 MB (Free: 12889.6 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 19, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 19, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 19, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 19, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 19, 样本 200
    将执行 5 轮本地训练

全局轮次 20/20
训练前 | GPU: 3411.4/16303.0 MB (Free: 12891.6 MB) | RAM: 1187.5 MB
清理后 轮次20 | GPU: 3411.4/16303.0 MB (Free: 12891.6 MB) | RAM: 1187.5 MB
当前活跃张量数: 3227, 总大小: 7.89 MB
本轮训练耗时: 0.08秒
  评估进度: 样本 0/250
    客户端1开始本地训练: 全局轮次 20, 样本 0
    将执行 5 轮本地训练
  评估进度: 样本 50/250
    客户端1开始本地训练: 全局轮次 20, 样本 50
    将执行 5 轮本地训练
  评估进度: 样本 100/250
    客户端1开始本地训练: 全局轮次 20, 样本 100
    将执行 5 轮本地训练
  评估进度: 样本 150/250
    客户端1开始本地训练: 全局轮次 20, 样本 150
    将执行 5 轮本地训练
  评估进度: 样本 200/250
    客户端1开始本地训练: 全局轮次 20, 样本 200
    将执行 5 轮本地训练

  当前轮次 20 的MSE为: 0.007650, MAE为: 0.087462
  模型已保存到: checkpoints/FedGPAI_400_20/epoch_20.pt
FedGPAI的MSE为：0.007649540901184082
FedGPAI的标准差为：0.004401315003633499
